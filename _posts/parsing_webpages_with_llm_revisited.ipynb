{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing webpages with a Large Language Model (LLM) revisited\n",
    "\n",
    "![](../_img/robot_looking_at_website.png)\n",
    "\n",
    "[I previously wrote about parsing websites and extract structured data](https://hdembinski.github.io/posts/parsing_webpages_with_llm.html), but that was in January 2025 and a lot has happened in the LLM sphere since then. The pace at which development moves forward is truly mind-boggling. Since then, I changed my mind about a couple of things, especially regarding the libraries that I would recommend.\n",
    "\n",
    "#### llama.cpp > ollama\n",
    "\n",
    "I won't praise `ollama` anymore, instead I'll recommend running [llama.cpp](https://github.com/ggml-org/llama.cpp). `ollama` is great to get a head start into the world of LLMs, because it makes installing and running your first LLM really easy, but the team behind it has shown behavior that raises red flags.\n",
    "\n",
    "- The project is essentially wrapping [llama.cpp](https://github.com/ggml-org/llama.cpp), but for a long time did not provide proper attribution, see [ollama-3697](https://github.com/ollama/ollama/issues/3697). Even now you need to scroll down the whole README to find that attribution, which seems unfair as all the hard engineering work to make LLMs run fast on consumer hardware is done by the `llama.cpp` team.\n",
    "- `ollama` introduced their own format for storing LLMs on device for no particular reason, which is incompatible with the standard GGUF format, meaning that you cannot easily switch to other tools to run the same models that you already downloaded.\n",
    "- `llama.cpp` compiled from sources preforms better than `ollama`.\n",
    "- `llama.cpp` provides more feature and allows for greater control of said features.\n",
    "\n",
    "#### PydanticAI > llama-index\n",
    "\n",
    "[In my post about RAG](https://hdembinski.github.io/posts/llama_index_rag.html), I advertised `llama-index`, which was based on a survey of several AI libraries. I have since discovered [PydanticAI](https://github.com/pydantic/pydantic-ai), which is from the same team that brought us the fantastic [Pydantic](https://github.com/pydantic/pydantic). Both libraries abstract away annoying details and boilerplate, while giving you layers of control from high-level down to the fundamentals, if you need it (and in the realm of LLMs, you often need to dig in deep). Most libraries only achieve the former, but fail at the latter. They also have excellent documentation. `PydanticAI` is great for extracting structured output, so we will use it here.\n",
    "\n",
    "## The task\n",
    "\n",
    "With that out of the way, let's revisit the task. In this post, I will let the LLM parse a web page to extract data and return it in a structured format. More specifically, I will read a couple of web pages from InspireHEP about a few scientific papers on which I am a co-author and then extract lists of references contained in these pages. Normally, one would write a parser to solve this task, but with LLMs we can skip that and just describe the task in human language. With the advent of strong coding models, there is also an interesting third option, the hybrid approach, where we let LLM write the grammar for a parser based on a bunch of example documents. The hybrid approach is arguably the best one if the structure of the source documents changes only rarely, because it provides deterministic outcomes and is much more energy efficient than using a LLM. LLMs are great for one-shot or few-shot tasks, where writing a parser would not make sense.\n",
    "\n",
    "_Disclaimer:_ I'll note again that there are easier ways to solve this particular task: InspireHEP allows one to download information about papers in machine readable format (BibTeX and others). The point of this post is to show how to do it with an LLM, because that approach can also be used for other pages that do not offer access to their data in machine-readable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dynamic web pages to Markdown\n",
    "\n",
    "The code for this part was written by ChatGPT. We use Playwright to render the HTML a user would see in an actual browser. That's important, because many websites are rendered dynamically with JavaScript, so that the raw HTML code does not contain the information we seek. Since the HTML downloaded by Playwright is still very cluttered and hard to read, we convert it with `markdownify` into simple Markdown, which is easier to read by humans and LLMs. This step removes lots of the HTML noise that deals with formatting. In signal processing terms, we increase the signal-to-noise ratio of the data. We save the Markdown files in the subdirectory `scraped`.\n",
    "\n",
    "On Windows, [the Playwright code cannot be run inside a Jupyter notebook](https://github.com/microsoft/playwright-python/issues/178#issuecomment-1062232487), it is a long-standing issue. `Playwright` refuses to use its sync API when it detects that an event loop is running, and its async API fails on Windows with a `NotImplementedError`.\n",
    "\n",
    "As a workaround, I run the code in a separate process, using `joblib`. If we weren't running from a Jupyter notebook, we could also use a `concurrent.future.ProcessPoolExecutor`, but that doesn't work in a notebook. `joblib` does some magic behind the scenes to enable this. As a sideeffect, this enables us to scrape multiple websites in parallel. We need to careful doing that too much, though, because websites, including Inspire, tend to block IPs that make too many calls in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skipped scraped\\\\inspirehep_net_literature_1889335.md',\n",
       " 'Skipped scraped\\\\inspirehep_net_literature_2512593.md',\n",
       " 'Skipped scraped\\\\inspirehep_net_literature_2017107.md',\n",
       " 'Skipped scraped\\\\inspirehep_net_literature_2687746.md',\n",
       " 'Skipped scraped\\\\inspirehep_net_literature_2727838.md']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "\n",
    "def scrape_to_markdown(url: str, output_dir: Path):\n",
    "    from playwright.sync_api import sync_playwright\n",
    "    from markdownify import markdownify as md\n",
    "\n",
    "    output_fn = url[url.index(\"://\") + 3 :].replace(\"/\", \"_\").replace(\".\", \"_\") + \".md\"\n",
    "    ofile = output_dir / output_fn\n",
    "    if ofile.exists():\n",
    "        return f\"Skipped {ofile}\"\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "\n",
    "        page = browser.new_page()\n",
    "        page.goto(url)\n",
    "        # Wait for JavaScript-rendered content to load\n",
    "        page.wait_for_load_state(\"networkidle\")\n",
    "        rendered_html = page.content()\n",
    "        page.close()\n",
    "        markdown_content = md(rendered_html)\n",
    "\n",
    "        with open(ofile, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(markdown_content)\n",
    "\n",
    "        browser.close()\n",
    "        return f\"Saved {ofile}\"\n",
    "\n",
    "\n",
    "scraped = Path() / \"scraped\"\n",
    "\n",
    "urls = \"\"\"\n",
    "https://inspirehep.net/literature/1889335\n",
    "https://inspirehep.net/literature/2512593\n",
    "https://inspirehep.net/literature/2017107\n",
    "https://inspirehep.net/literature/2687746\n",
    "https://inspirehep.net/literature/2727838\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "joblib.Parallel(n_jobs=4)(\n",
    "    joblib.delayed(scrape_to_markdown)(url, scraped) for url in urls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of an example files looks like this:\n",
    "\n",
    "```markdown\n",
    "Measurement of prompt charged-particle production in pp collisions at $ \\sqrt{\\mathrm{s}} $ = 13 TeV - INSPIREYou need to enable JavaScript to run this app.\n",
    "\n",
    "[INSPIRE Logo](/)\n",
    "\n",
    "literature\n",
    "\n",
    "- Help\n",
    "- Submit\n",
    "- [Login](/user/login)\n",
    "\n",
    "[Literature](/literature)\n",
    "\n",
    "[Authors](/authors)\n",
    "\n",
    "[Jobs](/jobs)\n",
    "\n",
    "[Seminars](/seminars)\n",
    "\n",
    "[Conferences](/conferences)\n",
    "\n",
    "[Data](/data)BETA\n",
    "\n",
    "More...\n",
    "\n",
    "## Measurement of prompt charged-particle production in pp collisions at s \\sqrt{\\mathrm{s}} s​ = 13 TeV\n",
    "\n",
    "- [LHCb](/literature?q=collaboration:LHCb)\n",
    "\n",
    "Collaboration\n",
    "\n",
    "•\n",
    "\n",
    "- [Roel Aaij](/authors/1070843)(\n",
    "\n",
    "  - [Nikhef, Amsterdam](/institutions/903832)\n",
    "\n",
    "  )\n",
    "\n",
    "Show All(972)\n",
    "\n",
    "Jul 28, 2021\n",
    "\n",
    "35 pages\n",
    "\n",
    "Published in:\n",
    "\n",
    "- _JHEP_ 01 (2022) 166\n",
    "\n",
    "- Published: Jan 27, 2022\n",
    "\n",
    "e-Print:\n",
    "\n",
    "- [2107.10090](//arxiv.org/abs/2107.10090) [hep-ex]\n",
    "\n",
    "DOI:\n",
    "\n",
    "- [10.1007/JHEP01(2022)166](<//doi.org/10.1007/JHEP01(2022)166>)\n",
    "\n",
    "Report number:\n",
    "\n",
    "- LHCb-PAPER-2021-010,\n",
    "- CERN-EP-2021-110\n",
    "\n",
    "Experiments:\n",
    "\n",
    "- [CERN-LHC-LHCb](/experiments/1110643)\n",
    "\n",
    "View in:\n",
    "\n",
    "- [CERN Document Server](http://cds.cern.ch/record/2777220),\n",
    "- [HAL Science Ouverte](https://hal.science/hal-03315290),\n",
    "- [ADS Abstract Service](https://ui.adsabs.harvard.edu/abs/arXiv:2107.10090)\n",
    "\n",
    "pdfciteclaim[datasets](/data/?q=literature.record.$ref:1889335)\n",
    "\n",
    "[reference search](/literature?q=citedby:recid:1889335)[32 citations](/literature?q=refersto:recid:1889335)\n",
    "\n",
    "### Citations per year\n",
    "\n",
    "[...]\n",
    "```\n",
    "\n",
    "The web page also contains all the references cited by the paper. I skipped that part here, which is not of interest for us. In fact, one should cut that part away in order to help the model focus on the relevant text piece and to not waste time on processing irrelevant tokens.\n",
    "\n",
    "The converted Markdown does not look perfect, the conversion garbled up the structure of the document. Let's see whether the LLM can make sense of this raw text. We want it to extract the authors, the journal data, the title, and the DOI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from raw text with a LLM\n",
    "\n",
    "In the original post, I used natural language to describe the structure of the output I want. Since then, models have become much better at returning structured output in form of JSON, and `PydanticAI` provides convenient tooling to return structured output with validation.\n",
    "\n",
    "We don't use `ollama` this time, but `llama.cpp` directly. For the model, we use the capable `Qwen-2.5-coder-7b-instruct` with the Q8_K quant and a 64000 token context window. It's lauded on Reddit to be a good coding model for its size, and since a lot of computer code contains JSON, it should be good at producing that. I also experimented with some other models, see comments below.\n",
    "\n",
    "We need to start the `llama-server` separately. There is no native support in `PydanticAI` for `llama.cpp` at this time, but since `llama-server` is OpenAI compatible, we merely need to adapt the OpenAI provider. This is an example of the great flexibility in `PydanticAI` that I mentioned at the beginning of the post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Measurement of prompt charged-particle production in pp collisions at s √{s} s\\u200b = 13 TeV'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Roel Aaij'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'LHCb'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'JHEP'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'01'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2107.10090'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1007/JHEP01(2022)166'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'LHCb-PAPER-2021-010'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'CERN-EP-2021-110'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'Measurement of prompt charged-particle production in pp collisions at s √\u001b[0m\u001b[32m{\u001b[0m\u001b[32ms\u001b[0m\u001b[32m}\u001b[0m\u001b[32m s\\u200b = 13 TeV'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Roel Aaij'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'LHCb'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'JHEP'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'01'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m166\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2107.10090'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1007/JHEP01\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m166'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'LHCb-PAPER-2021-010'\u001b[0m, \u001b[32m'CERN-EP-2021-110'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The Muon Puzzle in cosmic-ray induced air showers and its connection to the Large Hadron Collider'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Johannes Albrecht'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Lorenzo Cazon'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Hans Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Anatoli Fedynitch'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Karl-Heinz Kampert'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Astrophys.Space Sci.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2105.06148'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1007/s10509-022-04054-5'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'The Muon Puzzle in cosmic-ray induced air showers and its connection to the Large Hadron Collider'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Johannes Albrecht'\u001b[0m, \u001b[32m'Lorenzo Cazon'\u001b[0m, \u001b[32m'Hans Dembinski'\u001b[0m, \u001b[32m'Anatoli Fedynitch'\u001b[0m, \u001b[32m'Karl-Heinz Kampert'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'Astrophys.Space Sci.'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'367'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m27\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2105.06148'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1007/s10509-022-04054-5'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A new maximum-likelihood method for template fits'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Hans Peter Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ahmed Abdelmotteleb'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Eur.Phys.J.C'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'82'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1043</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2206.12346'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1140/epjc/s10052-022-11019-z'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'A new maximum-likelihood method for template fits'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Hans Peter Dembinski'\u001b[0m, \u001b[32m'Ahmed Abdelmotteleb'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'Eur.Phys.J.C'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'82'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m1043\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2206.12346'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1140/epjc/s10052-022-11019-z'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The muon measurements of Haverah Park and their connection to the muon puzzle'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'L. Cazon'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'H.P. Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'G. Parente'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F. Riehn'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A.A. Watson'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'PoS'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ICRC2023'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">431</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.22323/1.444.0431'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'The muon measurements of Haverah Park and their connection to the muon puzzle'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'L. Cazon'\u001b[0m, \u001b[32m'H.P. Dembinski'\u001b[0m, \u001b[32m'G. Parente'\u001b[0m, \u001b[32m'F. Riehn'\u001b[0m, \u001b[32m'A.A. Watson'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'PoS'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'ICRC2023'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m431\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2023\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.22323/1.444.0431'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bias, variance, and confidence intervals for efficiency estimators in particle physics experiments'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Hans Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Michael Schmelling'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2110.00294'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'Bias, variance, and confidence intervals for efficiency estimators in particle physics experiments'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Hans Dembinski'\u001b[0m, \u001b[32m'Michael Schmelling'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2021\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2110.00294'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic_ai import Agent, ModelSettings, capture_run_messages\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from pydantic.networks import HttpUrl\n",
    "from pydantic.types import PositiveInt\n",
    "from rich import print\n",
    "\n",
    "# Here we define the schema for the reference we want to extract.\n",
    "class Reference(BaseModel):\n",
    "    title: str\n",
    "    \"Title of the paper\"\n",
    "    authors: list[str]\n",
    "    \"Authors, in the format 'First name Last name'\"\n",
    "    collaborations: list[str]\n",
    "    \"Collaborations involved in the paper, may be empty\"\n",
    "    journal: str | None\n",
    "    \"Journal name, leave empty if not published in a journal\"\n",
    "    volume: str | None\n",
    "    \"Volume, leave empty if not published in a journal\"\n",
    "    issue: PositiveInt | None\n",
    "    \"Issue number, leave empty if not provided\"\n",
    "    page: PositiveInt | None\n",
    "    \"Starting page number, leave empty if not published in a journal\"\n",
    "    year: PositiveInt\n",
    "    \"Year of publication\"\n",
    "    eprint: HttpUrl | None\n",
    "    \"URL to the arXiv preprint, leave empty if it is not provided\"\n",
    "    doi: str | None\n",
    "    \"DOI of the paper, leave empty if not provided\"\n",
    "    reports: list[str]\n",
    "    \"Report associated with the paper, leave empty if not provided\"\n",
    "\n",
    "    # enable docstrings for attributes\n",
    "    model_config = ConfigDict(use_attribute_docstrings=True)\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    OpenAIChatModel(\n",
    "        \"\",\n",
    "        provider=OpenAIProvider(base_url=\"http://localhost:8080/v1\"),\n",
    "        settings=ModelSettings(temperature=0.5, max_tokens=1000),\n",
    "    ),\n",
    "    output_type=Reference,\n",
    "    system_prompt=\"Extract a reference from the provided markdown.\",\n",
    "    instructions=\"\"\"\n",
    "- If you encounter LaTeX commands, copy them verbatim.\n",
    "- Journal references come in two formats:\n",
    "    - *journal* volume (year) issue, page\n",
    "    - *journal* volume (year) page [leave issue empty in this case]\n",
    "- Volume is not always numeric.\n",
    "- If two numbers follow the year in parentheses, and they are separated by a comma, the first is the issue, the second is the page.\n",
    "- Reports, if they exist, are listed after \"Report number:\". If this block doesn't exist, leave the `reports` field empty.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "documents = [fn.open(encoding=\"utf-8\").read() for fn in scraped.glob(\"*.md\")]\n",
    "\n",
    "# Trim off everything after the \"### Citations per year\" heading\n",
    "documents = [doc[: doc.index(\"### Citations per year\")] for doc in documents]\n",
    "\n",
    "\n",
    "for doc in documents:\n",
    "    with capture_run_messages() as messages:\n",
    "        try:\n",
    "            result = await agent.run(doc)\n",
    "            print(result.output)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # If there is an error (typically a schema validation error),\n",
    "            # print the messages for debugging.\n",
    "            print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are amazing and much more consistent and detailed than those obtained in January. Thanks to LLM training and `PydanticAI`, the output of the LLM is constrained to follow the schema, and can be readily consumed by a program. The model is also clever enough to find the relevant information on the website, even without us describing were to look. I noticed issues with detecting the `issue` and `reports`, but instructions to the model in natural language fixed those.\n",
    "\n",
    "`PydanticAI` enforces a good prompt structure and good practices, with its split of `system_prompt` and `instructions` and embedding information about the output format into the JSON schema.\n",
    "\n",
    "For a proper validation of the accuracy, we would have to run validation tests against a ground truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Testing other models\n",
    "\n",
    "I tested this with some other models, all of which performed worse on this task that the chosen one. Some models work better or at all with the `NativeOutput` mode of `PydanticAI`.\n",
    "\n",
    "- Qwen-2.5-coder-7b-instruct: Q8_0\n",
    "    - Works very well out of the box, some small issues were fixed with prompting. Reduced performance with Pydantic's `NativeOutput` mode.\n",
    "- gpt-oss-20b: mxfp4\n",
    "    - Couldn't adhere to the format, it failed to produce valid URLs for the `eprint` field.\n",
    "- Gemma-3-12b-it: Q4_0\n",
    "    - Doesn't work with Pydantic, it's complaining that user and model messages must alternate.\n",
    "- Qwen3-4B-Thinking-2507: Q6_K\n",
    "    - Fails to return the result via tool call. It works with `NativeOutput`, but fails to produce valid<br>URLs for the `eprint` field.\n",
    "\n",
    "Some issues that these models have, like those with the `eprint` field, could probably be fixed with prompts that address the specific errors.\n",
    "\n",
    "Seeing how sensitive the performance is to prompting, even when the task is to produce well-structured output, **gives me pause about trusting public benchmarks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
