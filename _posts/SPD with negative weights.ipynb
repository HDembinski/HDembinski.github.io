{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the SPD approximation to negative weights\n",
    "\n",
    "In [Bohm and Zech, NIMA 748 (2014) 1-6](https://doi.org/10.1016/j.nima.2014.02.021), the scaled Poisson distribution is discussed, which is an approximate distribution for sums of weights. This distribution is used in fits to histograms which are filled with weighted samples.\n",
    "\n",
    "I demonstrate here that a fit based on the SPD performs better than a least-squares fit, which effectively uses a normal distribution instead of the SPD to describe random fluctuations. I run repeated simulations in which weighted samples are generated. They are filled into a generalized histogram that keeps track of the variance of the weights. The cost function for the fit is simple: all bins in the histogram have the same constant expectation. The cost is computed with the least-squares method and the SPD method, respectively.\n",
    "\n",
    "I measure the bias and the variance of the results in repeated toy experiments. The SPD-based cost function yields a smaller bias and the estimated uncertainty better reflects the true variance of the fit results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from iminuit import Minuit\n",
    "from scipy.stats import norm\n",
    "import boost_histogram as bh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def cost_lsq(w, wvar, mu):\n",
    "    r = 0.0\n",
    "    for i in range(len(w)):\n",
    "        if wvar[i] > 0:\n",
    "            r += (w[i] - mu) ** 2 / wvar[i]\n",
    "    return r\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def cost_ml(w, wvar, mu):\n",
    "    # Bohm and Zech, NIMA 748 (2014) 1-6\n",
    "    r = 0.0\n",
    "    for i in range(len(w)):\n",
    "        if wvar[i] > 0 and w[i] * mu > 0:\n",
    "            s_inv = w[i] / wvar[i]\n",
    "            mu_prime = mu * s_inv\n",
    "            n_prime = w[i] * s_inv      \n",
    "            r += mu_prime - n_prime * np.log(mu_prime)\n",
    "    return 2 * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSQ\n",
      "  relative bias = -0.042\n",
      "  average estimated variance 1.966, true variance 2.158\n",
      "ML\n",
      "  relative bias = -0.001\n",
      "  average estimated variance 2.008, true variance 2.035\n"
     ]
    }
   ],
   "source": [
    "nmc = 1000\n",
    "\n",
    "def run(cost, w_mu, w_sigma_rel, mu_pts, bins):\n",
    "    expected_mu = w_mu * mu_pts / bins\n",
    "    rng = np.random.default_rng(seed=1)\n",
    "    fitted_mu = []\n",
    "    fitted_mu_var = []\n",
    "    h = bh.Histogram(bh.axis.Regular(bins, 0, 1), storage=bh.storage.Weight())\n",
    "    for imc in range(nmc):\n",
    "        h.reset()\n",
    "        n = rng.poisson(mu_pts)\n",
    "        x = rng.uniform(size=n)\n",
    "        wi = rng.normal(w_mu, w_sigma_rel * w_mu, size=n)\n",
    "        h.fill(x, weight=wi)\n",
    "        m = Minuit(lambda mu: cost(h.values(), h.variances(), mu), mu=expected_mu)\n",
    "        m.limits[\"mu\"] = (0, None)\n",
    "        m.migrad()\n",
    "        if m.valid:\n",
    "            fitted_mu.append(m.values[0])\n",
    "            fitted_mu_var.append(m.errors[0] ** 2)\n",
    "        else:\n",
    "            print(\"error\", imc)\n",
    "    \n",
    "    bias = np.mean(fitted_mu) - expected_mu\n",
    "    sample_var = np.var(fitted_mu, ddof=1)\n",
    "    mean_fitted_var = np.mean(fitted_mu_var)\n",
    "    return expected_mu, bias, mean_fitted_var, sample_var\n",
    "\n",
    "results = tuple(map(lambda cost: run(cost, 1.0, 0.1, 100, 5), (cost_lsq, cost_ml)))\n",
    "results = np.array(results)\n",
    "\n",
    "labels = \"LSQ\", \"ML\"\n",
    "for label, (expected_mu, bias, mean_fitted_var, sample_var ) in zip(labels, results):\n",
    "    print(label)\n",
    "    print(f\"  relative bias = {bias / expected_mu:.3f}\")\n",
    "    print(f\"  average estimated variance {mean_fitted_var ** 0.5:.3f}, true variance {sample_var ** 0.5:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
