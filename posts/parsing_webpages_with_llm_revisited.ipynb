{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing webpages with a Large Language Model (LLM) revisited\n",
    "\n",
    "[I previously wrote about parsing websites and extract structured data](https://hdembinski.github.io/posts/parsing_webpages_with_llm.html), but that was in January 2025 and a lot has happened in the LLM sphere since then. The pace at which development moves forward is truly mind-boggling. Since then, I changed my mind about a couple of things, especially regarding the libraries that I would recommend.\n",
    "\n",
    "#### llama.cpp > ollama\n",
    "\n",
    "I won't praise `ollama` anymore, instead I'll recommend running [llama.cpp](https://github.com/ggml-org/llama.cpp). `ollama` is great to get a head start into the world of LLMs, because it makes installing and running your first LLM really easy, but the team behind it has shown behavior that raises red flags.\n",
    "* The project is essentially wrapping [llama.cpp](https://github.com/ggml-org/llama.cpp), but for a long time did not provide proper attribution, see [ollama-3697](https://github.com/ollama/ollama/issues/3697). Even now you need to scroll down the whole README to find out that attribution, which seems unfair as all the hard engineering work to make LLMs run fast on consumer hardware is done by the `llama.cpp` team.\n",
    "* They introduced their own format for storing LLMs, which is incompatible with the standard GGUF format, meaning that you cannot easily switch to other tools to run the same models that you already downloaded.\n",
    "* The performance is worse compared to `llama.cpp` compiled from sources.\n",
    "\n",
    "#### PydanticAI > llama-index\n",
    "\n",
    "[In my post about RAG](https://hdembinski.github.io/posts/llama_index_rag.html), I advertised `llama-index`, which was based on a survey of several AI libraries. I have since discovered [PydanticAI](https://github.com/pydantic/pydantic-ai), which is from the same team that brought us the fantastic [Pydantic](https://github.com/pydantic/pydantic). Both libraries abstract away annoying details and boilerplate, while giving you layers of control from high-level down to the fundamentals, if you need it (and in the realm of LLMs, you often need to dig in deep). Most libraries only achieve the former, but fail at the latter. They also have excellent documentation. `PydanticAI` is great for extracting structured output, so we will use it here.\n",
    "\n",
    "## The task\n",
    "\n",
    "With that out of the way, let's revisit the task. In this post, I will let the LLM parse a web page to extract data and return it in a structured format. More specifically, I will read a couple of web pages from InspireHEP about a few scientific papers on which I am a co-author and then extract lists of references contained in these pages. Normally, one would write a parser to solve this task, but with LLMs we can skip that and just describe the task in human language. With the advent of strong coding models, there is also an interesting third option, the hybrid approach, where we let LLM write the grammar for a parser based on a bunch of example documents. The hybrid approach is arguably the best one if the structure of the source documents changes only rarely, because it provides deterministic outcomes and is much more energy efficient than using a LLM. LLMs are great for one-shot or few-shot tasks, where writing a parser would not make sense.\n",
    "\n",
    "*Disclaimer:* I'll note again that there are easier ways to solve this particular task: InspireHEP allows one to download information about papers in machine readable format (BibTeX and others). The point of this post is to show how to do it with an LLM, because that approach can also be used for other pages that do not offer access to their data in machine-readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dynamic web pages to Markdown\n",
    "\n",
    "The code for this part was written by ChatGPT. At least on Windows, the Playwright code cannot be run inside a Jupyter notebook, so I have to use a script. The script first produces the dynamically generated HTML via a remote controlled browser, and then converts it to Markdown and saves the Markdown files in the subdirectory `scraped`. Markdownify, when it works, is a great helper, because it greatly simplifies (denoises) the original HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to run async code in Jupyter notebooks, \n",
    "# as we will do later with PydanticAI.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['c:\\\\Users\\\\hansd.Powercat\\\\source\\\\blog\\\\.venv\\\\Scripts\\\\python.exe', 'c:\\\\Users\\\\hansd.Powercat\\\\source\\\\blog\\\\posts\\\\scrape.py', 'https://inspirehep.net/literature/1889335', 'https://inspirehep.net/literature/2512593', 'https://inspirehep.net/literature/2017107', 'https://inspirehep.net/literature/2687746', 'https://inspirehep.net/literature/2727838', '-d', 'c:\\\\Users\\\\hansd.Powercat\\\\source\\\\blog\\\\posts\\\\scraped'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "script = r\"\"\"\n",
    "from playwright.async_api import async_playwright\n",
    "from markdownify import markdownify as md\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import asyncio\n",
    "from rich.progress import track\n",
    "from rich import print\n",
    "\n",
    "\n",
    "async def scrape_to_markdown(url: str, output_dir: Path):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        output_fn = (\n",
    "            url[url.index(\"://\") + 3 :].replace(\"/\", \"_\").replace(\".\", \"_\") + \".md\"\n",
    "        )\n",
    "        ofile = output_dir / output_fn\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        await page.goto(url)\n",
    "\n",
    "        # Wait for JavaScript-rendered content to load\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "\n",
    "        rendered_html = await page.content()\n",
    "\n",
    "        await page.close()\n",
    "\n",
    "        markdown_content = md(rendered_html)\n",
    "\n",
    "        with open(ofile, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(markdown_content)\n",
    "\n",
    "        print(f\"Saved {ofile}\")\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Scrape web pages and save them as Markdown files.\"\n",
    "    )\n",
    "    parser.add_argument(\"url\", nargs=\"+\", type=str, help=\"URL to scrape.\")\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--output-dir\",\n",
    "        type=Path,\n",
    "        default=\".\",\n",
    "        help=\"Directory to save the scraped Markdown files.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for url in track(args.url):\n",
    "        await scrape_to_markdown(url, args.output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "\"\"\"\n",
    "\n",
    "cwd = Path().absolute()\n",
    "\n",
    "with open(cwd / \"scrape.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script)\n",
    "\n",
    "\n",
    "urls = '''\n",
    "https://inspirehep.net/literature/1889335\n",
    "https://inspirehep.net/literature/2512593\n",
    "https://inspirehep.net/literature/2017107\n",
    "https://inspirehep.net/literature/2687746\n",
    "https://inspirehep.net/literature/2727838\n",
    "'''.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "subprocess.run([sys.executable, str(cwd / \"scrape.py\"), *urls, \"-d\", str(cwd / \"scraped\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of an example files looks like this:\n",
    "\n",
    "```markdown\n",
    "Measurement of prompt charged-particle production in pp collisions at $ \\sqrt{\\mathrm{s}} $ = 13 TeV - INSPIREYou need to enable JavaScript to run this app.\n",
    "\n",
    "[INSPIRE Logo](/)\n",
    "\n",
    "literature\n",
    "\n",
    "* Help\n",
    "* Submit\n",
    "* [Login](/user/login)\n",
    "\n",
    "[Literature](/literature)\n",
    "\n",
    "[Authors](/authors)\n",
    "\n",
    "[Jobs](/jobs)\n",
    "\n",
    "[Seminars](/seminars)\n",
    "\n",
    "[Conferences](/conferences)\n",
    "\n",
    "[Data](/data)BETA\n",
    "\n",
    "More...\n",
    "\n",
    "Measurement of prompt charged-particle production in pp collisions at s \\sqrt{\\mathrm{s}} s​ = 13 TeV\n",
    "-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "* [LHCb](/literature?q=collaboration:LHCb)\n",
    "\n",
    " Collaboration\n",
    "\n",
    "•\n",
    "\n",
    "* [Roel Aaij](/authors/1070843)(\n",
    "\n",
    "  + [Nikhef, Amsterdam](/institutions/903832)\n",
    "\n",
    "  )\n",
    "\n",
    "Show All(972)\n",
    "\n",
    "Jul 28, 2021\n",
    "\n",
    "35 pages\n",
    "\n",
    "Published in: \n",
    "\n",
    "* *JHEP* 01 (2022) 166\n",
    "\n",
    "* Published: Jan 27, 2022\n",
    "\n",
    "e-Print: \n",
    "\n",
    "* [2107.10090](//arxiv.org/abs/2107.10090) [hep-ex]\n",
    "\n",
    "DOI: \n",
    "\n",
    "* [10.1007/JHEP01(2022)166](//doi.org/10.1007/JHEP01(2022)166)\n",
    "\n",
    "Report number: \n",
    "\n",
    "* LHCb-PAPER-2021-010,\n",
    "* CERN-EP-2021-110\n",
    "\n",
    "Experiments: \n",
    "\n",
    "* [CERN-LHC-LHCb](/experiments/1110643)\n",
    "\n",
    "View in: \n",
    "\n",
    "* [CERN Document Server](http://cds.cern.ch/record/2777220),\n",
    "* [HAL Science Ouverte](https://hal.science/hal-03315290),\n",
    "* [ADS Abstract Service](https://ui.adsabs.harvard.edu/abs/arXiv:2107.10090)\n",
    "\n",
    "pdfciteclaim[datasets](/data/?q=literature.record.$ref:1889335)\n",
    "\n",
    "[reference search](/literature?q=citedby:recid:1889335)[32 citations](/literature?q=refersto:recid:1889335)\n",
    "\n",
    "### Citations per year\n",
    "\n",
    "[...]\n",
    "```\n",
    "\n",
    "The web page also contains all the references cited by the paper. I skipped that part here, which is not of interest for us. In fact, one should cut that part away in order to help the model focus on the relevant text piece and to not waste time on processing irrelevant tokens.\n",
    "\n",
    "The converted Markdown does not look perfect, the conversion garbled up the structure of the document. Let's see whether the LLM can make sense of this raw text. We want it to extract the authors, the journal data, the title, and the DOI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from raw text with a LLM\n",
    "\n",
    "In the original post, I used natural language to describe the structure of the output I want. Since then, models have become much better at returning structured output in form of JSON, and `PydanticAI` provides convenient tooling to return structured output with validation.\n",
    "\n",
    "We don't use `ollama` this time, but `llama.cpp` directly. For the model, we use the capable `Qwen-2.5-coder-7b-instruct` with the Q8_K quant and a 64000 token context window. Why Qwen-2.5? It's lauded to be a good coding model for its size, and a lot of computer code contains JSON, so it should be good at producing that. I also experimented with the newer `Qwen3-4B-Thinking-2507`, but found that it doesn't work with `PydanticAI` very well. It was producing the output in its thinking box, instead of the response for the user.\n",
    "\n",
    "We need to start the `llama-server` separately. There is no native support in `PydanticAI` for `llama.cpp` at this time, but since `llama-server` is OpenAI compatible, we merely need to adapt the OpenAI provider. This is the great flexibility in `PydanticAI` that I mentioned at the beginning of the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Measurement of prompt charged-particle production in pp collisions at s √{s} s\\u200b = 13 TeV'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Roel Aaij'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'LHCb'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'JHEP'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'01'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2107.10090'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1007/JHEP01(2022)166'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'LHCb-PAPER-2021-010'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'CERN-EP-2021-110'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'Measurement of prompt charged-particle production in pp collisions at s √\u001b[0m\u001b[32m{\u001b[0m\u001b[32ms\u001b[0m\u001b[32m}\u001b[0m\u001b[32m s\\u200b = 13 TeV'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Roel Aaij'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'LHCb'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'JHEP'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'01'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m166\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2107.10090'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1007/JHEP01\u001b[0m\u001b[32m(\u001b[0m\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m166'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'LHCb-PAPER-2021-010'\u001b[0m, \u001b[32m'CERN-EP-2021-110'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The Muon Puzzle in cosmic-ray induced air showers and its connection to the Large Hadron Collider'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Johannes Albrecht'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Lorenzo Cazon'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Hans Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Anatoli Fedynitch'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Karl-Heinz Kampert'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Astrophys.Space Sci.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2105.06148'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1007/s10509-022-04054-5'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'The Muon Puzzle in cosmic-ray induced air showers and its connection to the Large Hadron Collider'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Johannes Albrecht'\u001b[0m, \u001b[32m'Lorenzo Cazon'\u001b[0m, \u001b[32m'Hans Dembinski'\u001b[0m, \u001b[32m'Anatoli Fedynitch'\u001b[0m, \u001b[32m'Karl-Heinz Kampert'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'Astrophys.Space Sci.'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'367'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m27\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2105.06148'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1007/s10509-022-04054-5'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'A new maximum-likelihood method for template fits'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Hans Peter Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ahmed Abdelmotteleb'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Eur.Phys.J.C'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'82'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1043</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2206.12346'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.1140/epjc/s10052-022-11019-z'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'A new maximum-likelihood method for template fits'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Hans Peter Dembinski'\u001b[0m, \u001b[32m'Ahmed Abdelmotteleb'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'Eur.Phys.J.C'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'82'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[1;36m11\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m1043\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2022\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2206.12346'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.1140/epjc/s10052-022-11019-z'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The muon measurements of Haverah Park and their connection to the muon puzzle'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'L. Cazon'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'H.P. Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'G. Parente'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'F. Riehn'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A.A. Watson'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'PoS'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ICRC2023'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">431</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'10.22323/1.444.0431'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'The muon measurements of Haverah Park and their connection to the muon puzzle'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'L. Cazon'\u001b[0m, \u001b[32m'H.P. Dembinski'\u001b[0m, \u001b[32m'G. Parente'\u001b[0m, \u001b[32m'F. Riehn'\u001b[0m, \u001b[32m'A.A. Watson'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[32m'PoS'\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[32m'ICRC2023'\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[1;36m431\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2023\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[32m'10.22323/1.444.0431'\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reference</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bias, variance, and confidence intervals for efficiency estimators in particle physics experiments'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">authors</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Hans Dembinski'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Michael Schmelling'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">collaborations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">journal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">volume</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">issue</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">year</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">eprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HttpUrl</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'https://arxiv.org/abs/2110.00294'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">doi</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reports</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mReference\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtitle\u001b[0m=\u001b[32m'Bias, variance, and confidence intervals for efficiency estimators in particle physics experiments'\u001b[0m,\n",
       "    \u001b[33mauthors\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Hans Dembinski'\u001b[0m, \u001b[32m'Michael Schmelling'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcollaborations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mjournal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mvolume\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33missue\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mpage\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33myear\u001b[0m=\u001b[1;36m2021\u001b[0m,\n",
       "    \u001b[33meprint\u001b[0m=\u001b[1;35mHttpUrl\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'https://arxiv.org/abs/2110.00294'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdoi\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mreports\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic_ai import Agent, ModelSettings, capture_run_messages\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from pydantic.networks import HttpUrl\n",
    "from pydantic.types import PositiveInt\n",
    "from rich import print\n",
    "\n",
    "\n",
    "# Here we define the schema for the reference we want to extract.\n",
    "class Reference(BaseModel):\n",
    "    title: str\n",
    "    \"Title of the paper\"\n",
    "    authors: list[str]\n",
    "    \"Authors, in the format 'First name Last name'\"\n",
    "    collaborations: list[str]\n",
    "    \"Collaborations involved in the paper, may be empty\"\n",
    "    journal: str | None\n",
    "    \"Journal name, leave empty if not published in a journal\"\n",
    "    volume: str | None\n",
    "    \"Volume, leave empty if not published in a journal\"\n",
    "    issue: PositiveInt | None\n",
    "    \"Issue number, leave empty if not provided\"\n",
    "    page: PositiveInt | None\n",
    "    \"Starting page number, leave empty if not published in a journal\"\n",
    "    year: PositiveInt\n",
    "    \"Year of publication\"\n",
    "    eprint: HttpUrl | None\n",
    "    \"URL to the arXiv preprint, leave empty if it is not provided\"\n",
    "    doi: str | None\n",
    "    \"DOI of the paper, leave empty if not provided\"\n",
    "    reports: list[str]\n",
    "    \"Report associated with the paper, leave empty if not provided\"\n",
    "\n",
    "    # enable docstrings for attributes\n",
    "    model_config = ConfigDict(use_attribute_docstrings=True)\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    OpenAIChatModel(\n",
    "        \"\",\n",
    "        provider=OpenAIProvider(base_url=\"http://localhost:8080/v1\"),\n",
    "        settings=ModelSettings(temperature=0.2, max_tokens=1000),\n",
    "    ),\n",
    "    output_type=Reference,\n",
    "    system_prompt=\"Extract a reference using the tool call from the provided markdown.\",\n",
    "    instructions=\"\"\"\n",
    "- If you encounter LaTeX commands, copy them verbatim.\n",
    "- Journal references come in two formats:\n",
    "    - *journal* volume (year) issue, page\n",
    "    - *journal* volume (year) page [leave issue empty in this case]\n",
    "- Volume is not always numeric.\n",
    "- If two numbers follow the year in parentheses, and they are separated by a comma, the first is the issue, the second is the page.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "documents = [fn.open(encoding=\"utf-8\").read() for fn in (cwd / \"scraped\").glob(\"*.md\")]\n",
    "\n",
    "# Trim off everything after the \"### Citations per year\" section\n",
    "documents = [doc[: doc.index(\"### Citations per year\")] for doc in documents]\n",
    "\n",
    "\n",
    "for doc in documents:\n",
    "    with capture_run_messages() as messages:\n",
    "        try:\n",
    "            result = await agent.run(doc)\n",
    "            print(result.output)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # If there is an error (typically a schema validation error),\n",
    "            # print the messages for debugging.\n",
    "            print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are amazing and much more consistent and detailed than those obtained in January. Thanks to LLM training and `PydanticAI`, the output of the LLM is constrained to follow the schema, and can be readily consumed by a program. The model is also clever enough to find the relevant information on the website, even without us describing were to look. I noticed some issues with detecting the `issue`, which the model first attributed wrongly, but the additional instructions to the model in natural language seemed to have fixed that. \n",
    "\n",
    "`PydanticAI` enforces a good prompt structure and good practices, with its split of `system_prompt` and `instructions` and embedding information about the output format into the JSON schema.\n",
    "\n",
    "For a proper validation of the accuracy, we would have to run validation tests against a ground through, of course, so take these results with a caution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
